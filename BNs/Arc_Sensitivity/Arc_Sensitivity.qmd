---
title: "Assessing the Effect of Bayesian Network Arc Removal on the Calculated Likelihood Ratio"
---

# Introduction
Understanding how BNs work and what the effect of networks created by different practitioners is key to supporting robust, reproducible science. As networks become more complex there has been a move to save sub-networks of common processes to allow for reuse in other networks. These are termed OOBNs, which has opened the door to the creation of highly complex and large networks by embedding the sub-networks within the larger network. 
Assessment of the network to determine the effect of the values used is important to ensure the evaluation is robust and limitations are understood (Schaapveld 2019, Chen and Pollino 2012). Although there have been many advancements in causal model algorithms in the field of artificial intelligence in recent years, there is a lag in the transparency or explainability of outputs derived from these complex models that makes them less attractive to a forensic or legal context.
Whether a node is included in a network is at the discretion of the practitioner and is based on the framework of circumstance and their assumptions. The effect of different practitioners can be modelled by modifying the architecture of a BN for a case by removing arcs between nodes.  This changes the state probabilities of the child node so that it is no longer conditional on the parent. Determining changes in the resultant likelihood ratio value that is obtained will describe the sensitivity to networks created by different practitioners for the same case.

```{r setup}
#| echo: false
#| warning: false
#| include: false

sapply(
  c("dplyr","bnlearn","gRain","BiocManager"),
  FUN=function (x){
    if(!x %in% installed.packages()){
      install.packages(x) }
    })

 sapply(
  c( "Rgraphviz"),
  FUN=function (x){
    if(!x %in% installed.packages()){
      BiocManager::install(x) }
    })  
library("dplyr")
library("bnlearn")
library("gRain")

```


# Methods
### Importing and Visualisation of a Toy Network
A simple BN (shown in @fig-simpleBN) was created in Hugin Expert Software (Andersen 1989) and then imported into R (v4.4.1) using the BNLearn package. 

![A simple BN created using Hugin](../../Thesis/assets/toyNetworkLabels.png){#fig-simpleBN}

```{r}
originalNetwork  <- read.net("simpleBNexample.net")
```

The network was then visualised with probabilities showing using graphviz to ensure that it was consistent with Hugin
```{r}
# origPlot <- graphviz.plot(originalNetwork,
#   groups = list(
#     c("HpHd", "Activity2", "Activity3"),
#     c("TPPR4", "TPPR5", "TPPR6", "Results7")
#   )
# )

graphviz.chart(originalNetwork,
                            type = "barprob",
                            grid = TRUE, 
                            bar.col = "darkgreen",
                            strip.bg = "lightskyblue")

```

### Set Seed for Reproducibility
```{r}
set.seed(123) 
```



Initially, I attempted to identify and then iterate through the edges, removing and calculating the marginal probabilities with sampling with replacement. This would work if the nodes needed to change from conditional probabilities to unconditional probabilities for the child nodes but not when only one condition is removed. 

## Identifying the arcs
```{r}
arcs <- arcs(originalNetwork)
nrow <- length(arcs[, 1])
```


# simulate the marginal distributions of the original network (on a new copy to not overwrite the original import)
```{r}
origBN <- originalNetwork
sim_data <- rbn(origBN, n = 100000)
```

## Loop through the list of arcs, identifying parent and child, drop the arc and recreate and replace the CPT
```{r}
for (i in 1:nrow) {
  print(i)
  parent <- arcs[[i, "from"]]
  child <- arcs[[i, "to"]]
  set.seed(123)  # For reproducibility
  bn_structure <- bn.net(origBN)
  newBN <- drop.arc(bn_structure, parent, child)
  # graphviz.plot(newBN) #
  new_data <- cptable(child,
    levels=levels(sim_data[, which(names(sim_data) == child)]),
    values = table(sim_data[ , which(names(sim_data) == child)])/nrow(sim_data)
  )

  replace_cpt(as.grain(origBN), new_data)
  ```

As networks become more complex, an iterative loop becomes a non-viable method due to computational runtime.
More work is needed to investigate possible methods to assess the effect of node inclusion. Possible methods include Monte Carlo, or MCMC methods.

## Try with Monte Carlo Sampling
  ```{r}
  tempBN_fitted <- bn.fit(newBN, sim_data) #[ , - which(names(sim_data) == child)])

  tempBN_pred  <- predict(tempBN_fitted,
    data = data.frame(Results7 = factor("Yes", levels = c("Yes", "No"))),
    node = "HpHd",
    method = "bayes-lw",
    n = 10000,
    prob = TRUE
  ) # Generate 10,000 samples if results true
```

  # Compute empirical marginal distributions
  ```{r}
  marginal_HpHd <- attributes(tempBN_pred)$prob

  cat("Empirical Marginals via Monte Carlo Sampling:\n")
  cat("P(HpHd):\n")
  print(marginal_HpHd)

  print(marginal_HpHd[1]/ marginal_HpHd[2])

}
```


Consider computation using maths to deal with multiple parents
```{r}
#bnlearn::BF(numerator, denom) computes bayes factor between two networks
# P(Child∣Remaining Parents)= ∑ P(Child∣Parents,Remaining Parents)⋅P(Parents)

new_prob <- querygrain(tempBN, nodes = child, type = "conditional")* querygrain(tempBN, nodes = parent, type = "conditional")

```



